{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ethancpwoo/Practice-NeuralNetwork/blob/main/DogsvCats.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rCeEMEcL0M87"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 225/225 [00:01<00:00, 156.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0. Loss: 0.19333547353744507\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 225/225 [00:01<00:00, 192.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1. Loss: 0.16906605660915375\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 225/225 [00:01<00:00, 185.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 2. Loss: 0.1388191282749176\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2494/2494 [00:01<00:00, 1761.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy:  0.711\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from ast import arg\n",
        "import os\n",
        "from re import L\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn \n",
        "import torch.nn.functional as F \n",
        "import torch.optim as optim\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "\n",
        "\n",
        "REBUILD_DATA = False #set true only once, unless you want to change something in training data\n",
        "device = torch.device(\"cuda:0\")\n",
        "\n",
        "class DogsVSCats(): \n",
        "    IMG_SIZE = 50\n",
        "    CATS = \"kagglecatsanddogs_5340/PetImages/Cat\" #getting images from folders\n",
        "    DOGS = \"kagglecatsanddogs_5340/PetImages/Dog\"\n",
        "    LABELS = {CATS: 0, DOGS: 1} #1d vector, cats are 0 and dogs r 1\n",
        "    training_data = [] #array for trainset\n",
        "    catcount = 0\n",
        "    dogcount = 0\n",
        "\n",
        "    def make_training_data(self): #making the training data\n",
        "        for label in self.LABELS: #for each label, cats and dogs\n",
        "            for f in tqdm(os.listdir(label)): #go through every single file \n",
        "                if \"jpg\" in f: \n",
        "                    try:\n",
        "                        path = os.path.join(label, f) #join method of cat or dog and jpg. Find path of it\n",
        "                        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE) #read the image from path, then grayscale\n",
        "                        img = cv2.resize(img, (self.IMG_SIZE, self.IMG_SIZE)) #resize the image \n",
        "                        self.training_data.append([np.array(img), np.eye(2)[self.LABELS[label]]]) #add to the training_data array both the image and the label\n",
        "                        if label == self.CATS: \n",
        "                            self.catcount += 1\n",
        "                        elif label == self.DOGS: \n",
        "                            self.dogcount += 1\n",
        "                    except Exception as e: \n",
        "                        pass \n",
        "\n",
        "        np.random.shuffle(self.training_data) #shuffle the data\n",
        "        np.save(\"training_data.npy\", self.training_data)\n",
        "        print('Cats:',dogsvcats.catcount)\n",
        "        print('Dogs:',dogsvcats.dogcount)\n",
        "    \n",
        "if REBUILD_DATA:\n",
        "    dogsvcats = DogsVSCats()\n",
        "    dogsvcats.make_training_data() \n",
        "\n",
        "training_data = np.load(\"training_data.npy\", allow_pickle=True) #array\n",
        "X = torch.Tensor([i[0] for i in training_data]).view(-1, 50, 50) #Convert to tensor and view as 50 by 50 2d tensor for image px by px\n",
        "X = X/255.0 #idk what this does actually\n",
        "y = torch.Tensor([i[1] for i in training_data]) #this is whether it is dog or cat (labels)\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self): \n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 5) # 1 image input, 32 output channel, 5*5 kernel/window\n",
        "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 5)\n",
        "\n",
        "        x = torch.randn(50,50).view(-1, 1, 50, 50) #random tensor to pass through nn\n",
        "        self._to_linear = None\n",
        "        self.convs(x)\n",
        "\n",
        "        self.fc1 = nn.Linear(self._to_linear, 512) #this value can only be found when we pass an experimental tensor through the neural network\n",
        "        self.fc2 = nn.Linear(512, 2) #we just flattened here \n",
        "    \n",
        "    def convs(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) #from first convolutional layer, rectify linear\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2)) #maxpool2d essentially takes essential parts and shrinks them\n",
        "        x = F.max_pool2d(F.relu(self.conv3(x)), (2, 2)) #2,2 is the window size\n",
        "\n",
        "        if self._to_linear is None: \n",
        "            self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2] #from the data x, get size of first part of data * by size other dims \n",
        "        return x \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convs(x) #run data through convolutional layers run first\n",
        "        x = x.view(-1, self._to_linear) #flatten data\n",
        "        x = F.relu(self.fc1(x)) #run data thru linear layers\n",
        "        x = self.fc2(x) #output layer, no need for activation\n",
        "        return F.softmax(x, dim = 1)\n",
        "\n",
        "net = Net().to(device)#make neural network object \n",
        "optimizer = optim.Adam(net.parameters(), lr = 0.001) #make optimizer object\n",
        "loss_function = nn.MSELoss() #make loss function object\n",
        "MODEL_NAME = f\"model-{int(time.time())}\" #gives a dynamic model name to make things unique and sorted\n",
        "\n",
        "X = torch.Tensor([i[0] for i in training_data]).view(-1, 50, 50) #make tensor of pixels training data\n",
        "X = X/255.0 #i forgot why we did this rewatch\n",
        "y = torch.Tensor([i[1] for i in training_data]) #make tensor of dog or cat \n",
        "\n",
        "VAL_PCT = 0.1\n",
        "val_size = int(len(X)*VAL_PCT)\n",
        "train_X = X[:-val_size] #simple python splicing of arrays to seperate test and train\n",
        "train_y = y[:-val_size]\n",
        "test_X = X[-val_size:]\n",
        "test_y = y[-val_size:]\n",
        "\n",
        "BATCH_SIZE = 100\n",
        "EPOCHS = 3\n",
        "\n",
        "def train(net):\n",
        "    with open(\"model.log\", \"a\") as f:\n",
        "        for epoch in range(EPOCHS):\n",
        "            for i in tqdm(range(0, len(train_X), BATCH_SIZE)): #for every batch, tqdm shows loading bar\n",
        "                batch_X = train_X[i:i+BATCH_SIZE].view(-1, 1, 50, 50) \n",
        "                batch_y = train_y[i:i+BATCH_SIZE]\n",
        "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "                #net.zero_grad() #idk what zero gradienting does i forgot\n",
        "                #outputs = net(batch_X) #put the image through nn\n",
        "                #matches = [torch.argmax(i) == torch.argmax(j) for i, j in zip(outputs, batch_y)] #find the mathes between outputs of nn and if it is cat and dog\n",
        "                #in_sample_acc = matches.count(True)/len(matches) #just counting accuracy \n",
        "                #loss = loss_function(outputs, batch_y) #put if it is cat or dog and answer of nn through loss functipon\n",
        "                #loss.backward() #actually use the loss function\n",
        "                #optimizer.step() #optimize the nn \n",
        "\n",
        "                acc, loss = fwd_pass(batch_X, batch_y, train = True)\n",
        "                #f.write(f\"{MODEL_NAME},{round(time.time(), 3)}, in_sample, {round(float(acc), 2)}, {round(float(loss),4)}\")\n",
        "                if i % 10 == 0:\n",
        "                    val_acc, val_loss = test(size = 100)\n",
        "                    f.write(f\"{MODEL_NAME},{round(time.time(), 3)}, {round(float(acc), 2)}, {round(float(loss),4)}, {round(float(val_acc), 2)}, {round(float(val_loss),4)}\\n\")\n",
        "\n",
        "            print(f\"Epoch: {epoch}. Loss: {loss}\")\n",
        "\n",
        "def batch_test(net): \n",
        "    BATCH_SIZE = 100\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        batch_X = test_X[:BATCH_SIZE].view(-1, 1, 50, 50)\n",
        "        batch_y = test_y[:BATCH_SIZE]\n",
        "\n",
        "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "\n",
        "        net.zero_grad()\n",
        "        outputs = net(batch_X)\n",
        "\n",
        "        matches = [torch.argmax(i)==torch.argmax(j) for i, j in zip(outputs, batch_y)]\n",
        "        acc = matches.count(True)/len(matches) #same as above\n",
        "        print(\"Test Accuracy: \", round(acc, 3))\n",
        "\n",
        "def fwd_pass(X, y, train=False):\n",
        "    if train:\n",
        "        net.zero_grad()\n",
        "    outputs = net(X)\n",
        "    matches = [torch.argmax(i)==torch.argmax(j) for i, j in zip(outputs, y)]\n",
        "    acc = matches.count(True)/len(matches) #same as above\n",
        "    loss = loss_function(outputs, y)\n",
        "\n",
        "    if train:\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    return acc, loss\n",
        "\n",
        "\n",
        "def test(net):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad(): #testing the nn\n",
        "        for i in tqdm(range(len(test_X))): #through the length of the test set\n",
        "            real_class = torch.argmax(test_y[i]).to(device) #real class, what it actually is \n",
        "            net_out = net(test_X[i].view(-1, 1, 50, 50).to(device))[0] #how the neural network views the class\n",
        "            predicted_class = torch.argmax(net_out) #the output of the nn\n",
        "\n",
        "            if predicted_class == real_class: #count if they real and predicted are the same \n",
        "                correct += 1\n",
        "            total +=1\n",
        "    print(\"Accuracy: \", round(correct/total, 3)) #percentage of accuracy to 3 decimal points`\n",
        "\n",
        "train(net)\n",
        "batch_test(net)\n",
        "\n",
        "style.use(\"ggplot\")\n",
        "model_name = MODEL_NAME\n",
        "\n",
        "def create_acc_loss_graph(model_name):\n",
        "    contents = open(\"model.log\", \"r\").read().split(\"/n\")\n",
        "    times = []\n",
        "    accuracies = []\n",
        "    losses = []\n",
        "    val_accs = []\n",
        "    val_losses = []\n",
        "    \n",
        "    for c in contents: \n",
        "        if model_name in c:\n",
        "            name, timestamp, acc, loss, val_acc, val_loss = c.split(\",\")\n",
        "            times.append(float(timestamp))\n",
        "            accuracies.append(float(acc))\n",
        "            losses.append(float(loss))\n",
        "            val_accs.append(float(val_acc))\n",
        "            val_losses.append(float(val_loss))\n",
        "    fig = plt.figure()\n",
        "    ax1 = plt.subplot2grid((2,1), (0,0))\n",
        "    ax2 = plt.subplot2grid((2,1), (0,0), sharex = ax1)\n",
        "    ax1.plot(times, accuracies, label=\"acc\")\n",
        "    ax1.plot(times, val_accs, label=\"val_acc\")\n",
        "    ax1.legend(loc = 2)\n",
        "    ax2.plot(times, losses, label=\"loss\")\n",
        "    ax2.plot(times, val_losses, label=\"val_loss\")\n",
        "    plt.show()\n",
        "\n",
        "create_acc_loss_graph(model_name)   \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "    \n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "Welcome To Colaboratory",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "e51871c569916b212a5169136257eb9b772996936338bc66e712417a39169ea3"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
